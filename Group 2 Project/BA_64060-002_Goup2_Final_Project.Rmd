---
title: "Group 2 Project"
author: "Melissa Dennis, Stephen Gombos, Kyle Beeden"
date: "2025-12-06"
output: word_document
---
```{r}
#rm(list = ls())
##Load libraries

library(readr)  
library(dplyr)  
library(janitor)  
library(ggplot2)  
library(cluster)  
library(readxl)
library(tidyr)
library(factoextra)
```


```{r} 
##Load data

raw_df <- read_excel("C:/Users/kylej/OneDrive/Documents/BA 64060/Final Project/EIA923_Schedules_2_3_4_5_M_12_2023_Final.xlsx")

##Isolate the last 6 columns and remove the first 4 rows
data_raw <- raw_df[-(1:4),]

##Use the first row as the column names
colnames(data_raw) <- data_raw[1,]

##Remove first row as this is now a duplicate row
data_raw <- data_raw[-(1),]

##Clean column names for easier use
df_cleaned <- data_raw %>% 
  clean_names()

head(df_cleaned)
```

```{r}
##Identify ID columns
id_vars <- c(
  "plant_id",
  "plant_name",
  "plant_state",
  "reported_fuel_type_code")

##Keep only columns listed in ID column vector, i.e., id_vars
df_ids <- df_cleaned %>%
  select(any_of(id_vars))


##Grab YTD columns (last 6 columns of the data frame) as recommended in directions
ytd_raw <- df_cleaned %>%
  select((ncol(.) - 5):ncol(.))

#See/check names of TYD columns
names(ytd_raw) 

```

```{r}
##Convert YTD columns to numeric
##Anything that cannot be converted will be turned to NA
ytd_numeric <- ytd_raw %>%
  mutate(across(everything(), ~ as.numeric(as.character(.))))

##Check NA per column
na_prop <- sapply(ytd_numeric, function(x) mean(is.na(x)))
na_prop


```
```{r}
##Directions are to remove variables with significant missing value, however, the above shows that there are none to remove

##Combine df_ids and ytd_numeric
df_for_cluster <- bind_cols(df_ids, ytd_numeric)

##This step drops NAs
df_complete <- df_for_cluster %>%
  tidyr::drop_na()

##See which rows were dropped for having NA value(s)
dropped_rows <- df_for_cluster %>%
  filter(!complete.cases(.))

dropped_rows

```
```{r}
##Remove ID columns for clustering
clustering_data <- df_complete %>%
  select(-plant_id, -plant_name, -plant_state, -reported_fuel_type_code, -year)

##Scale the numeric YTD columns
df_scaled <- scale(clustering_data)

```



```{r}
##Determine Optimal Number of Clusters K

##Elbow Method to choose K. Look for a bend in the plot.
##Test k from 1 to 8.
set.seed(123)
k_max <- 8

##Calculate the Within-Cluster Sum of Squares for each K
wcss <- sapply(1:k_max, function(k){
  kmeans(df_scaled, centers = k, nstart = 20, iter.max=100)$tot.withinss
})

##Visualize the Elbow Plot
elbow_plot <- data.frame(k = 1:k_max, wcss = wcss) %>%
  ggplot(aes(x = k, y = wcss)) +
  geom_line(color = "blue", linewidth = 1) +
  geom_point(color = "blue", size = 3) +
  labs(
    title = "Elbow Method to Determine Optimal K",
    x = "Number of Clusters (K)",
    y = "Within-Cluster Sum of Squares (WCSS)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(elbow_plot)

```

```{r}
##Double Check: Use silhouette method to determine the number of clusters
fviz_nbclust(df_scaled, kmeans, method = "silhouette")

```



```{r}
##Perform K-Means Clustering

##Based on the elbow plot, visually inspecting the bend 3 should be used for k. 

K_FINAL <- 3 
set.seed(123)
kmeans_result <- kmeans(df_scaled, centers = K_FINAL, nstart = 20)

##Attach the cluster assignment back to the original cleaned dataframe
df_clustered <- df_complete %>%
  mutate(cluster = as.factor(kmeans_result$cluster))

df_clustered %>%
  count(cluster)
```
```{r}
##Summarize the key features by cluster to identify what makes them different
cluster_summary <- df_clustered %>%
  group_by(cluster) %>%
  summarise(
    across(where(is.numeric), ~ mean(.x, na.rm = TRUE), .names = "avg_{.col}"),
    most_common_fuel  = names(which.max(table(reported_fuel_type_code))),
    most_common_state = names(which.max(table(plant_state))),
    n_plants = n(),
    .groups = "drop"
  )

cluster_summary
```
```{r}
##Visualization for identifying outlines/problems
##Using Principal Component Analysis to reduce features down to 2 components so we can plot the clusters on a 2D graph.
pca_result <- prcomp(df_scaled, scale. = FALSE)
pca_data <- as.data.frame(pca_result$x) %>%
  mutate(cluster = df_clustered$cluster)

##Plot the clusters using the first two principal components (PC1 and PC2)
cluster_plot <- pca_data %>%
  ggplot(aes(x = PC1, y = PC2, color = cluster)) +
  geom_point(alpha = 0.6) + # Plot all points
  geom_point(data = filter(pca_data, cluster == cluster_summary$cluster[1]), 
             size = 4, shape = 1, color = "black") + # Highlight the smallest cluster (potential problem/outlier)
  labs(
    title = paste("Plant/Fuel Profiles Clustered (K=", K_FINAL, ")"),
    subtitle = "Visualized using the first two Principal Components (PC1 and PC2)",
    caption = "Smallest cluster is highlighted with a black border."
  ) +
  scale_color_discrete(name = "Cluster") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(cluster_plot)
```
```{r}
##Visualization - Cluster plot
fviz_cluster(kmeans_result, data = df_scaled,) 
```

```{r}
##Problem Identification

##The problem is likely found in the smallest cluster.
##This cluster contains observations that are statistically distinct from the rest of the data.
##Filter the original data to inspect the problematic/unique data points:

potential_problem_cluster <- cluster_summary %>%
  arrange(n_plants) %>%      # sort by size
  slice(1) %>%               # take the smallest
  pull(cluster)              # extract the cluster label

problem_data_points <- df_clustered %>%
  filter(cluster == potential_problem_cluster) %>%
  select(
    plant_id,
    plant_name,
    plant_state,
    reported_fuel_type_code,
    net_generation_megawatthours,
    total_fuel_consumption_quantity,
    total_fuel_consumption_mm_btu,
    cluster)

print(paste("--- Potential Problem/Anomaly Data Points (Cluster", potential_problem_cluster, ") ---"))
print(problem_data_points)
```